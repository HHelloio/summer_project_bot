import telebot
from telebot import types
import io
from PyPDF2 import PdfReader
import ollama
import time
import torch
import chardet
from docx import Document
import numpy as np
from sentence_transformers import SentenceTransformer
import faiss
import os
from dotenv import load_dotenv
from duckduckgo_search import DDGS
import nltk
from nltk.tokenize import sent_tokenize
from sentence_transformers import util
import networkx as nx 
from dataclasses import dataclass
from typing import List


nltk.download('punkt')

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv('token.env')
token = os.getenv("TELEGRAM_BOT_TOKEN")
bot = telebot.TeleBot(token=token)
#TELEGRAM_BOT_TOKEN=8068131419:AAF1kLt_l9GDOZrc4MRMMxGECLd_pXMzblQ

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
all_texts = []
saved_requests = []
text_chunks = []
faiss_index = None
model_name = "gemma3:12b"
WEB_SEARCH_ENABLED = True  # –§–ª–∞–≥ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è/–≤—ã–∫–ª—é—á–µ–Ω–∏—è –≤–µ–±-–ø–æ–∏—Å–∫–∞
chunk_graph = None  # –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞—Ñ–∞

@dataclass
class ChunkMeta:
    id: int
    doc_id: int
    text: str
    position: int  # –ü–æ–∑–∏—Ü–∏—è —á–∞–Ω–∫–∞ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
EMBEDDING_DIM = 384

# ======== –ù–ê–°–¢–†–û–ô–ö–ò –†–ï–ñ–ò–ú–ê ========
DEBUG_MODE = True  # –í–∫–ª—é—á–∞–µ–º –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏


# ==================================

def check_gpu_support():
    pytorch_cuda = torch.cuda.is_available()
    ollama_gpu = False
    try:
        model_info = ollama.show(model_name)
        ollama_gpu = "gpu" in model_info.get('details', {}).get('backend', 'cpu')
    except Exception as e:
        if DEBUG_MODE:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ Ollama GPU: {e}")
    return pytorch_cuda or ollama_gpu

gpu_available = check_gpu_support()
if DEBUG_MODE:
    print(f"GPU –¥–æ—Å—Ç—É–ø–µ–Ω: {gpu_available}")

def check_ollama_connection(retries=5, delay=3):
    for i in range(retries):
        try:
            ollama.list()
            if DEBUG_MODE:
                print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Ollama —É—Å–ø–µ—à–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
            return True
        except Exception as e:
            if DEBUG_MODE:
                print(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {i + 1}/{retries}: –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è - {str(e)}")
            time.sleep(delay)
    if DEBUG_MODE:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Ollama")
    return False

if not check_ollama_connection() and DEBUG_MODE:
    print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Å–µ—Ä–≤–µ—Ä Ollama –∑–∞–ø—É—â–µ–Ω (–∫–æ–º–∞–Ω–¥–∞: ollama serve)")

def extract_text_from_txt(file_bytes: bytes) -> str:
    try:
        encoding_detection = chardet.detect(file_bytes)
        encoding = encoding_detection['encoding'] or 'utf-8'
        confidence = encoding_detection['confidence']

        if DEBUG_MODE:
            print(f"–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∞: {encoding} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2%})")

        text = file_bytes.decode(encoding)

        if 'ÔøΩ' in text and confidence < 0.9:
            alternative_encodings = ['cp1251', 'iso-8859-5', 'koi8-r', 'cp866']
            for alt_enc in alternative_encodings:
                try:
                    text = file_bytes.decode(alt_enc)
                    if DEBUG_MODE:
                        print(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞: {alt_enc}")
                    break
                except:
                    continue
        return text

    except Exception as e:
        if DEBUG_MODE:
            print(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        try:
            return file_bytes.decode('utf-8', errors='ignore')
        except:
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞"


def extract_text_from_pdf(file_bytes: bytes) -> str:
    try:
        reader = PdfReader(io.BytesIO(file_bytes))
        text = ""

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç
        for page in reader.pages:
            text += page.extract_text() or ""

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ (–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –∑–∞–º–µ—Ç–∫–∏)
            if '/Annots' in page:
                for annot in page['/Annots']:
                    annot_obj = annot.get_object()
                    if '/Contents' in annot_obj:
                        text += "\n" + annot_obj['/Contents']

        return text

    except Exception as e:
        error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ PDF: {str(e)}"
        if DEBUG_MODE:
            print(error_msg)
        return error_msg


def extract_text_from_docx(file_bytes: bytes) -> str:
    try:
        doc = Document(io.BytesIO(file_bytes))
        text = []

        # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
        for para in doc.paragraphs:
            if para.text.strip():
                text.append(para.text)

        # –¢–∞–±–ª–∏—Ü—ã
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    if cell.text.strip():
                        text.append(cell.text)

        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –∏ –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª—ã
        for section in doc.sections:
            if section.header:
                for para in section.header.paragraphs:
                    if para.text.strip():
                        text.append(para.text)
            if section.footer:
                for para in section.footer.paragraphs:
                    if para.text.strip():
                        text.append(para.text)

        return "\n".join(text)

    except Exception as e:
        error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ DOCX: {str(e)}"
        if DEBUG_MODE:
            print(error_msg)
        return error_msg

def save_request(message):
    global saved_requests
    saved_requests.append(message.text)
    if DEBUG_MODE:
        print(saved_requests)
    bot.send_message(message.chat.id, f"‚úÖ –ó–∞–ø—Ä–æ—Å —Å–æ—Ö—Ä–∞–Ω—ë–Ω:\n\n{message.text}")
    process_request(message)

def split_into_chunks_sent_overlap(text: str, max_sentences: int = 10, overlap_sentences: int = 2) -> list[str]:
    sentences = sent_tokenize(text)
    chunks = []
    i = 0

    while i < len(sentences):
        end = i + max_sentences
        chunk = " ".join(sentences[i:end])
        chunks.append(chunk)
        i += max_sentences - overlap_sentences

    if DEBUG_MODE:
        print(f"[CHUNKING-SENT] –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤ —Å overlap={overlap_sentences}")
    return chunks

def split_into_chunks_word_overlap(text: str, max_words: int = 400, overlap_words: int = 50) -> list[str]:
    words = text.split()
    chunks = []
    i = 0

    while i < len(words):
        chunk = words[i:i + max_words]
        chunks.append(" ".join(chunk))
        i += max_words - overlap_words

    if DEBUG_MODE:
        print(f"[CHUNKING-WORD] –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤ —Å overlap={overlap_words} —Å–ª–æ–≤")
    return chunks

CHUNK_METHOD = "sentence"  # –∏–ª–∏ "word"

def split_into_chunks(text: str, doc_id: int = 0, **kwargs) -> List[ChunkMeta]:
    global CHUNK_METHOD
    raw_chunks = []

    if CHUNK_METHOD == "sentence":
        raw_chunks = split_into_chunks_sent_overlap(text, max_sentences=10, overlap_sentences=2)
    elif CHUNK_METHOD == "word":
        raw_chunks = split_into_chunks_word_overlap(text, max_words=400, overlap_words=50)
    else:
        raise ValueError("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –º–µ—Ç–æ–¥ —á–∞–Ω–∫–∏–Ω–≥–∞")

    chunks_with_meta = [
        ChunkMeta(
            id=i,
            doc_id=doc_id,
            text=chunk,
            position=i
        )
        for i, chunk in enumerate(raw_chunks)
    ]

    if DEBUG_MODE:
        print(f"[CHUNK_META] –î–æ–∫—É–º–µ–Ω—Ç {doc_id}: —Å–æ–∑–¥–∞–Ω–æ {len(chunks_with_meta)} —á–∞–Ω–∫–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏")

    return chunks_with_meta

def create_faiss_index(embeddings: np.ndarray):
    index = faiss.IndexFlatIP(EMBEDDING_DIM)
    faiss.normalize_L2(embeddings)
    index.add(embeddings)
    return index

def build_chunk_graph(chunks: list[ChunkMeta], threshold=0.7):
    G = nx.Graph()
    texts = [chunk.text for chunk in chunks]
    embeddings = embedding_model.encode(texts, convert_to_tensor=True)

    for i, chunk in enumerate(chunks):
        G.add_node(i, text=chunk.text, doc_id=chunk.doc_id, position=chunk.position)

    for i in range(len(chunks)):
        for j in range(i + 1, len(chunks)):
            sim = util.cos_sim(embeddings[i], embeddings[j]).item()
            if sim >= threshold:
                G.add_edge(i, j, weight=round(sim, 3))

    if DEBUG_MODE:
        print(f"[GRAPH] –ü–æ—Å—Ç—Ä–æ–µ–Ω –≥—Ä–∞—Ñ —Å {len(G.nodes)} —É–∑–ª–∞–º–∏ –∏ {len(G.edges)} —Ä—ë–±—Ä–∞–º–∏")
    return G

def process_and_embed_chunks() -> bool:
    global all_texts, text_chunks, faiss_index, chunk_graph

    if not all_texts:
        return False

    try:
        text_chunks = []
        for doc_id, doc_text in enumerate(all_texts):
            chunks = split_into_chunks(doc_text, doc_id=doc_id)
            text_chunks.extend(chunks)

        texts = [chunk.text for chunk in text_chunks]
        embeddings = embedding_model.encode(texts)

        faiss_index = create_faiss_index(embeddings)
        chunk_graph = build_chunk_graph(text_chunks)

        if DEBUG_MODE:
            print(f"–ò–Ω–¥–µ–∫—Å FAISS –ø–æ—Å—Ç—Ä–æ–µ–Ω. –í–µ–∫—Ç–æ—Ä–æ–≤: {faiss_index.ntotal}")
        return True

    except Exception as e:
        if DEBUG_MODE:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —á–∞–Ω–∫–æ–≤: {e}")
        return False

def find_relevant_chunks(query: str, top_k: int = 20, expand_with_graph: bool = True) -> list[str]:
    global faiss_index, text_chunks, chunk_graph

    if faiss_index is None or len(text_chunks) == 0:
        return []

    query_embedding = embedding_model.encode([query])
    faiss.normalize_L2(query_embedding)

    distances, indices = faiss_index.search(query_embedding, top_k * 2)

    selected_indices = []
    for i, dist in zip(indices[0], distances[0]):
        if dist > 0.1:
            selected_indices.append(i)
            if len(selected_indices) >= top_k:
                break

    if DEBUG_MODE:
        print(f"[FAISS] –ù–∞–π–¥–µ–Ω–æ {len(selected_indices)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤")

    expanded_indices = set(selected_indices)

    # –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ
    if expand_with_graph and chunk_graph:
        for idx in selected_indices:
            neighbors = list(chunk_graph.neighbors(idx))
            for neighbor in neighbors:
                if neighbor not in expanded_indices:
                    expanded_indices.add(neighbor)
                    if DEBUG_MODE:
                        sim = chunk_graph[idx][neighbor]['weight']
                        print(f"[GRAPH] –î–æ–±–∞–≤–ª–µ–Ω —Å–æ—Å–µ–¥ {neighbor} –∫ —á–∞–Ω–∫—É {idx} (—Å—Ö–æ–¥—Å—Ç–≤–æ={sim:.3f})")

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É –∏–Ω–¥–µ–∫—Å—É (–º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –¥—Ä—É–≥—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é)
    final_chunks = [text_chunks[i].text for i in sorted(expanded_indices)]

    if DEBUG_MODE:
        print(f"[CHUNKS] –§–∏–Ω–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤ –ø–æ—Å–ª–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è: {len(final_chunks)}")

    return final_chunks

def perform_web_search(query: str, max_results: int = 3) -> str:
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
    try:
        results = []
        with DDGS() as ddgs:
            for result in ddgs.text(query, max_results=max_results):
                results.append(f"‚Ä¢ [{result['title']}]({result['href']})\n{result['body']}")

        return "\n\n".join(results) if results else "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –∑–∞–ø—Ä–æ—Å—É –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞."

    except Exception as e:
        if DEBUG_MODE:
            print(f"–û—à–∏–±–∫–∞ –≤–µ–±-–ø–æ–∏—Å–∫–∞: {e}")
        return ""

def generate_response(prompt: str, context: str, web_context: str = "") -> str:
    try:
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –¥–≤—É–º—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞–º–∏
        full_prompt = (
            f"–¢—ã ‚Äî AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –∏—Å–ø–æ–ª—å–∑—É—è –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∏–∂–µ. –ü–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.\n\n"
            f"–ö–û–ù–¢–ï–ö–°–¢ –ò–ó –î–û–ö–£–ú–ï–ù–¢–û–í:\n{context}\n\n"
            f"–ö–û–ù–¢–ï–ö–°–¢ –ò–ó –ò–ù–¢–ï–†–ù–ï–¢–ê:\n{web_context}\n\n"
            f"–í–æ–ø—Ä–æ—Å: {prompt}\n\n"
            f"–û—Ç–≤–µ—Ç:"
        )

        options = {
            'temperature': 0.7,
            'num_predict': 3000,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç –æ—Ç–≤–µ—Ç–∞
            'top_p': 0.9
        }

        if gpu_available:
            options['num_gpu'] = 50

        response = ollama.generate(
            model=model_name,
            prompt=full_prompt,
            options=options
        )

        answer = response['response'].strip()
        # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω–æ–µ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞
        for phrase in [prompt, "–û—Ç–≤–µ—Ç:", "–í–æ–ø—Ä–æ—Å:"]:
            if answer.startswith(phrase):
                answer = answer[len(phrase):].strip()

        return answer

    except Exception as e:
        if DEBUG_MODE:
            print(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        return "‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."

def process_request(message):
    global all_texts, saved_requests, faiss_index, text_chunks, WEB_SEARCH_ENABLED

    if not all_texts:
        bot.send_message(message.chat.id, "‚ùå –ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞.")
        return

    if faiss_index is None or len(text_chunks) == 0:
        bot.send_message(message.chat.id,
                         "‚è≥ –°–æ–∑–¥–∞—é –∏–Ω–¥–µ–∫—Å –¥–ª—è –ø–æ–∏—Å–∫–∞... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")
        if not process_and_embed_chunks():
            bot.send_message(message.chat.id, "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–Ω–¥–µ–∫—Å–∞ –ø–æ–∏—Å–∫–∞.")
            return

    prompt = saved_requests[-1]
    bot.send_message(message.chat.id, "üîç –ò—â—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö...")
    relevant_chunks = find_relevant_chunks(prompt, top_k=5)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤

    if not relevant_chunks:
        bot.send_message(message.chat.id, "‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.")
        context = ""
    else:
        context = "\n\n".join(relevant_chunks)

    # –í–µ–±-–ø–æ–∏—Å–∫
    web_context = ""
    if WEB_SEARCH_ENABLED:
        #bot.send_message(message.chat.id, "üåê –ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ...")
        web_context = perform_web_search(prompt, max_results=3)
        if DEBUG_MODE:
            print(f"–í–µ–±-–∫–æ–Ω—Ç–µ–∫—Å—Ç: {web_context[:500]}...")

    if DEBUG_MODE:
        mode = "GPU" if gpu_available else "CPU"
        bot.send_message(message.chat.id, f"‚öôÔ∏è –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å (–Ω–∞ {mode})...")
        if context:
            bot.send_message(message.chat.id, f"üìö –ò—Å–ø–æ–ª—å–∑—É—é {len(relevant_chunks)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
        if web_context:
            bot.send_message(message.chat.id, "üåê –ò—Å–ø–æ–ª—å–∑—É—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–µ–±-–ø–æ–∏—Å–∫–∞")
    else:
        bot.send_message(message.chat.id, "‚öôÔ∏è –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...")

    bot.send_message(message.chat.id, "üß† –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç...")
    response = generate_response(prompt, context, web_context)

    # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ —á–∞—Å—Ç–∏
    max_length = 4000
    if len(response) > max_length:
        for i in range(0, len(response), max_length):
            bot.send_message(message.chat.id, response[i:i + max_length])
    else:
        bot.send_message(message.chat.id, f"üìù –û—Ç–≤–µ—Ç –Ω–∞ –≤–∞—à –∑–∞–ø—Ä–æ—Å:\n\n{response}")

def create_main_keyboard():
    markup = types.ReplyKeyboardMarkup(resize_keyboard=True)
    btn1 = types.KeyboardButton("–î–æ–±–∞–≤–∏—Ç—å —Ñ–∞–π–ª")
    btn2 = types.KeyboardButton('–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª')
    btn3 = types.KeyboardButton('–£–¥–∞–ª–∏—Ç—å –≤—Å–µ —Ñ–∞–π–ª—ã')
    btn4 = types.KeyboardButton("üìù –ù–∞–ø–∏—Å–∞—Ç—å –∑–∞–ø—Ä–æ—Å")
    btn6 = types.KeyboardButton("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–Ω–¥–µ–∫—Å")
    btn7 = types.KeyboardButton("üì• –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏–Ω–¥–µ–∫—Å")
    # –ö–Ω–æ–ø–∫–∞ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤–µ–±-–ø–æ–∏—Å–∫–æ–º
    btn_web = types.KeyboardButton("üåê –í–µ–±-–ø–æ–∏—Å–∫: –í–∫–ª" if WEB_SEARCH_ENABLED else "üåê –í–µ–±-–ø–æ–∏—Å–∫: –í—ã–∫–ª")

    if DEBUG_MODE:
        btn5 = types.KeyboardButton("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ")
        markup.add(btn1, btn2, btn3, btn4, btn5, btn6, btn7)
    else:
        markup.add(btn1, btn2, btn3)

    return markup

@bot.message_handler(commands=['start'])
def start(message):
    markup = create_main_keyboard()
    bot.send_message(message.chat.id,
                     "üëã –ü—Ä–∏–≤–µ—Ç! –Ø –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ. –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã (PDF, DOCX, TXT), –∞ –∑–∞—Ç–µ–º –∑–∞–¥–∞–≤–∞–π –≤–æ–ø—Ä–æ—Å—ã –ø–æ –∏—Ö —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É.",
                     reply_markup=markup)

@bot.message_handler(content_types=['text', 'document'])
def handle_files(message):
    global all_texts, text_chunks, faiss_index, saved_requests, WEB_SEARCH_ENABLED

    if message.document:
        file_info = bot.get_file(message.document.file_id)
        file_name = message.document.file_name
        file_bytes = bot.download_file(file_info.file_path)

        try:
            if file_name.lower().endswith('.txt'):
                text = extract_text_from_txt(file_bytes)
            elif file_name.lower().endswith('.pdf'):
                text = extract_text_from_pdf(file_bytes)
            elif file_name.lower().endswith(('.docx', '.doc')):
                text = extract_text_from_docx(file_bytes)
            else:
                bot.reply_to(message, '‚ùå –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã .txt, .pdf –∏ .docx')
                return

            all_texts.append(text)
            text_chunks = []
            faiss_index = None

            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∞–π–ª–µ
            if DEBUG_MODE:
                print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(all_texts)}")
                print(f"–†–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–∞: {len(text.split())} —Å–ª–æ–≤")
                print(f"–ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤: {text[:200]}...")

            bot.reply_to(message, f"üìÑ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω: {file_name}\n\n–¢–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω: {len(text.split())} —Å–ª–æ–≤")

        except Exception as er:
            error_msg = f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {er}"
            if DEBUG_MODE:
                error_msg += "\n\n–ü–æ–¥—Å–∫–∞–∑–∫–∞: –§–∞–π–ª –º–æ–∂–µ—Ç –∏–º–µ—Ç—å –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É –∏–ª–∏ –±—ã—Ç—å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω"
            bot.reply_to(message, error_msg)

    elif message.text:
        if message.text == 'üëã –ò —Ç–µ–±–µ –Ω–µ —Ö–≤–æ—Ä–∞—Ç—å':
            markup = create_main_keyboard()
            bot.send_message(message.chat.id, '–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:', reply_markup=markup)

        elif message.text == '–î–æ–±–∞–≤–∏—Ç—å —Ñ–∞–π–ª':
            bot.send_message(message.chat.id, '–ü—Ä–∏—Å—ã–ª–∞–π—Ç–µ —Ñ–∞–π–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ PDF, DOCX –∏–ª–∏ TXT')

        elif message.text == '–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª':
            if not all_texts:
                bot.send_message(message.chat.id, "‚ùå –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞.")
            else:
                bot.send_message(message.chat.id,
                                 "‚è≥ –°–æ–∑–¥–∞—é –∏–Ω–¥–µ–∫—Å –¥–ª—è –ø–æ–∏—Å–∫–∞... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")
                if process_and_embed_chunks():
                    bot.send_message(message.chat.id, f"‚úÖ –ò–Ω–¥–µ–∫—Å —Å–æ–∑–¥–∞–Ω! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(text_chunks)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
                else:
                    bot.send_message(message.chat.id, "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–Ω–¥–µ–∫—Å–∞")

        elif message.text == '–£–¥–∞–ª–∏—Ç—å –≤—Å–µ —Ñ–∞–π–ª—ã':
            all_texts = []
            saved_requests = []
            text_chunks = []
            faiss_index = None
            bot.send_message(message.chat.id, '‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã, –∑–∞–ø—Ä–æ—Å—ã –∏ –∏–Ω–¥–µ–∫—Å—ã —É–¥–∞–ª–µ–Ω—ã')

            # –î–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤ –Ω–∞ –¥–∏—Å–∫–µ
            try:
                os.remove("faiss_index.index")
            except FileNotFoundError:
                pass

            try:
                os.remove("text_chunks.pkl")
            except FileNotFoundError:
                pass

        elif message.text == 'üìù –ù–∞–ø–∏—Å–∞—Ç—å –∑–∞–ø—Ä–æ—Å':
            bot.send_message(message.chat.id, "–ù–∞–ø–∏—à–∏ —Å–≤–æ–π –∑–∞–ø—Ä–æ—Å –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:")
            bot.register_next_step_handler(message, save_request)
            


        elif message.text == 'üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–Ω–¥–µ–∫—Å':
            if faiss_index is None:
                bot.send_message(message.chat.id, "‚ùå –ò–Ω–¥–µ–∫—Å –Ω–µ —Å–æ–∑–¥–∞–Ω")
            else:
                try:
                    faiss.write_index(faiss_index, "faiss_index.index")
                    bot.send_message(message.chat.id, "‚úÖ –ò–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª faiss_index.index")
                except Exception as e:
                    bot.send_message(message.chat.id, f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {str(e)}")

        elif message.text == 'üì• –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏–Ω–¥–µ–∫—Å':
            if not os.path.exists("faiss_index.index"):
                bot.send_message(message.chat.id, "‚ùå –§–∞–π–ª –∏–Ω–¥–µ–∫—Å–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω")
            else:
                try:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é, –æ–±—ä—è–≤–ª–µ–Ω–Ω—É—é –≤ –Ω–∞—á–∞–ª–µ —Ñ—É–Ω–∫—Ü–∏–∏
                    faiss_index = faiss.read_index("faiss_index.index")
                    bot.send_message(message.chat.id,
                                     "‚úÖ –ò–Ω–¥–µ–∫—Å –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ —Ñ–∞–π–ª–∞\n‚ö†Ô∏è –¢–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã, –Ω—É–∂–Ω–æ –ø–µ—Ä–µ—Å—Ç—Ä–æ–∏—Ç—å –∏–Ω–¥–µ–∫—Å")
                except Exception as e:
                    bot.send_message(message.chat.id, f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}")

        elif message.text == '‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ' and DEBUG_MODE:
            try:
                pytorch_info = f"PyTorch: {torch.__version__}\nCUDA: {torch.cuda.is_available()}"
                emb_info = f"Embedding model: {embedding_model._modules['0'].auto_model.config._name_or_path}"
                faiss_info = f"FAISS: {faiss_index.ntotal} –≤–µ–∫—Ç–æ—Ä–æ–≤" if faiss_index else "FAISS: –∏–Ω–¥–µ–∫—Å –Ω–µ —Å–æ–∑–¥–∞–Ω"
                model_info = ollama.show(model_name)
                parameters = model_info.get('parameters', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                graph_info = f"–ì—Ä–∞—Ñ: {chunk_graph.number_of_nodes()} —É–∑–ª–æ–≤, {chunk_graph.number_of_edges()} —Ä—ë–±–µ—Ä" if chunk_graph else "–ì—Ä–∞—Ñ: –Ω–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω"


                info_msg = (
                    "‚öôÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ:\n"
                    f"‚Ä¢ –ú–æ–¥–µ–ª—å: {model_name}\n"
                    f"‚Ä¢ –†–µ–∂–∏–º: {'GPU' if gpu_available else 'CPU'}\n"
                    f"‚Ä¢ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {parameters}\n"
                    f"‚Ä¢ {emb_info}\n"
                    f"‚Ä¢ {faiss_info}\n\n"
                    f"PyTorch –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:\n{pytorch_info}"
                    f"‚Ä¢ {graph_info}\n"
                )

                bot.send_message(message.chat.id, info_msg)
            except Exception as e:
                bot.send_message(message.chat.id, f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {str(e)}")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–Ω–æ–ø–∫–∏ –≤–µ–±-–ø–æ–∏—Å–∫–∞
        elif message.text.startswith('üåê –í–µ–±-–ø–æ–∏—Å–∫:'):
            WEB_SEARCH_ENABLED = not WEB_SEARCH_ENABLED
            status = "–í–ö–õ–Æ–ß–ï–ù" if WEB_SEARCH_ENABLED else "–í–´–ö–õ–Æ–ß–ï–ù"
            bot.send_message(message.chat.id, f"–í–µ–±-–ø–æ–∏—Å–∫: {status}", reply_markup=create_main_keyboard())


bot.polling(none_stop=True, interval=0) 