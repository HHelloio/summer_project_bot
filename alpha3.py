import telebot
from telebot import types
import io
from PyPDF2 import PdfReader
import ollama
import time
import torch
import chardet
from docx import Document
import numpy as np
from sentence_transformers import SentenceTransformer
import faiss
import os
from tqdm import tqdm  # –î–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
from dotenv import load_dotenv



load_dotenv('token.env')
token = os.getenv("TELEGRAM_BOT_TOKEN")
bot = telebot.TeleBot(token=token)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
all_texts = []
saved_requests = []
text_chunks = []
faiss_index = None
model_name = "gemma3:12b"

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
EMBEDDING_DIM = 384

# ======== –ù–ê–°–¢–†–û–ô–ö–ò –†–ï–ñ–ò–ú–ê ========
DEBUG_MODE = False  # –í–∫–ª—é—á–∞–µ–º –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏


# ==================================

def check_gpu_support():
    pytorch_cuda = torch.cuda.is_available()
    ollama_gpu = False
    try:
        model_info = ollama.show(model_name)
        ollama_gpu = "gpu" in model_info.get('details', {}).get('backend', 'cpu')
    except Exception as e:
        if DEBUG_MODE:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ Ollama GPU: {e}")
    return pytorch_cuda or ollama_gpu


gpu_available = check_gpu_support()
if DEBUG_MODE:
    print(f"GPU –¥–æ—Å—Ç—É–ø–µ–Ω: {gpu_available}")


def check_ollama_connection(retries=5, delay=3):
    for i in range(retries):
        try:
            ollama.list()
            if DEBUG_MODE:
                print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Ollama —É—Å–ø–µ—à–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
            return True
        except Exception as e:
            if DEBUG_MODE:
                print(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {i + 1}/{retries}: –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è - {str(e)}")
            time.sleep(delay)
    if DEBUG_MODE:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Ollama")
    return False


if not check_ollama_connection() and DEBUG_MODE:
    print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Å–µ—Ä–≤–µ—Ä Ollama –∑–∞–ø—É—â–µ–Ω (–∫–æ–º–∞–Ω–¥–∞: ollama serve)")


def extract_text_from_txt(file_bytes: bytes) -> str:
    try:
        encoding_detection = chardet.detect(file_bytes)
        encoding = encoding_detection['encoding'] or 'utf-8'
        confidence = encoding_detection['confidence']

        if DEBUG_MODE:
            print(f"–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∞: {encoding} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2%})")

        text = file_bytes.decode(encoding)

        if 'ÔøΩ' in text and confidence < 0.9:
            alternative_encodings = ['cp1251', 'iso-8859-5', 'koi8-r', 'cp866']
            for alt_enc in alternative_encodings:
                try:
                    text = file_bytes.decode(alt_enc)
                    if DEBUG_MODE:
                        print(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞: {alt_enc}")
                    break
                except:
                    continue
        return text

    except Exception as e:
        if DEBUG_MODE:
            print(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        try:
            return file_bytes.decode('utf-8', errors='ignore')
        except:
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞"


def extract_text_from_pdf(file_bytes: bytes) -> str:
    try:
        reader = PdfReader(io.BytesIO(file_bytes))
        text = ""

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç
        for page in reader.pages:
            text += page.extract_text() or ""

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ (–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –∑–∞–º–µ—Ç–∫–∏)
            if '/Annots' in page:
                for annot in page['/Annots']:
                    annot_obj = annot.get_object()
                    if '/Contents' in annot_obj:
                        text += "\n" + annot_obj['/Contents']

        return text

    except Exception as e:
        error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ PDF: {str(e)}"
        if DEBUG_MODE:
            print(error_msg)
        return error_msg


def extract_text_from_docx(file_bytes: bytes) -> str:
    try:
        doc = Document(io.BytesIO(file_bytes))
        text = []

        # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
        for para in doc.paragraphs:
            if para.text.strip():
                text.append(para.text)

        # –¢–∞–±–ª–∏—Ü—ã
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    if cell.text.strip():
                        text.append(cell.text)

        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –∏ –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª—ã
        for section in doc.sections:
            if section.header:
                for para in section.header.paragraphs:
                    if para.text.strip():
                        text.append(para.text)
            if section.footer:
                for para in section.footer.paragraphs:
                    if para.text.strip():
                        text.append(para.text)

        return "\n".join(text)

    except Exception as e:
        error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ DOCX: {str(e)}"
        if DEBUG_MODE:
            print(error_msg)
        return error_msg


def save_request(message):
    global saved_requests
    saved_requests.append(message.text)
    if DEBUG_MODE:
        print(saved_requests)
    bot.send_message(message.chat.id, f"‚úÖ –ó–∞–ø—Ä–æ—Å —Å–æ—Ö—Ä–∞–Ω—ë–Ω:\n\n{message.text}")
    process_request(message)


def split_into_chunks(text: str, max_words: int = 400) -> list[str]:
    """–£–ª—É—á—à–µ–Ω–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    words = text.split()
    chunks = []
    current_chunk = []
    current_length = 0

    for word in words:
        if current_length + 1 <= max_words:
            current_chunk.append(word)
            current_length += 1
        else:
            chunks.append(" ".join(current_chunk))
            current_chunk = [word]
            current_length = 1

    if current_chunk:
        chunks.append(" ".join(current_chunk))

    return chunks


def create_faiss_index(embeddings: np.ndarray):
    index = faiss.IndexFlatIP(EMBEDDING_DIM)
    faiss.normalize_L2(embeddings)
    index.add(embeddings)
    return index


def process_and_embed_chunks() -> bool:
    global all_texts, text_chunks, faiss_index

    if not all_texts:
        return False

    try:
        text_chunks = []
        for doc in all_texts:
            chunks = split_into_chunks(doc, max_words=400)
            text_chunks.extend(chunks)

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        if DEBUG_MODE:
            total_words = sum(len(chunk.split()) for chunk in text_chunks)
            print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö: {total_words}")
            print(f"–°–æ–∑–¥–∞–Ω–æ {len(text_chunks)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
            print(f"–†–∞–∑–º–µ—Ä—ã –ø–µ—Ä–≤—ã—Ö 5 —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {[len(chunk.split()) for chunk in text_chunks[:5]]}")
            if text_chunks:
                print(f"–ü–µ—Ä–≤—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç: {text_chunks[0][:200]}...")

        embeddings = embedding_model.encode(text_chunks)
        faiss_index = create_faiss_index(embeddings)

        if DEBUG_MODE:
            print(f"–ò–Ω–¥–µ–∫—Å FAISS –ø–æ—Å—Ç—Ä–æ–µ–Ω. –í–µ–∫—Ç–æ—Ä–æ–≤: {faiss_index.ntotal}")
        return True

    except Exception as e:
        if DEBUG_MODE:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —á–∞–Ω–∫–æ–≤: {e}")
        return False


def find_relevant_chunks(query: str, top_k: int = 5) -> list[str]:
    global faiss_index, text_chunks

    if faiss_index is None or len(text_chunks) == 0:
        return []

    query_embedding = embedding_model.encode([query])
    faiss.normalize_L2(query_embedding)

    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º top_k –¥–ª—è –±–æ–ª—å—à–µ–π –ø–æ–ª–Ω–æ—Ç—ã
    distances, indices = faiss_index.search(query_embedding, top_k * 2)

    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
    relevant_chunks = []
    for i, dist in zip(indices[0], distances[0]):
        if dist > 0.3:  # –ü–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞
            relevant_chunks.append(text_chunks[i])
            if len(relevant_chunks) >= top_k:
                break

    if DEBUG_MODE:
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(relevant_chunks)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
        print(f"–°—Ö–æ–¥—Å—Ç–≤–∞: {distances[0][:len(relevant_chunks)]}")

    return relevant_chunks


def generate_response(prompt: str, context: str) -> str:
    try:
        full_prompt = (
            f"–¢—ã ‚Äî AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –∏—Å–ø–æ–ª—å–∑—É—è –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∏–∂–µ.\n\n"
            f"–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}\n\n"
            f"–í–æ–ø—Ä–æ—Å: {prompt}\n\n"
            f"–û—Ç–≤–µ—Ç:"
        )

        options = {
            'temperature': 0.7,
            'num_predict': 3000,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç –æ—Ç–≤–µ—Ç–∞
            'top_p': 0.9
        }

        if gpu_available:
            options['num_gpu'] = 50

        response = ollama.generate(
            model=model_name,
            prompt=full_prompt,
            options=options
        )

        answer = response['response'].strip()
        # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω–æ–µ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞
        for phrase in [prompt, "–û—Ç–≤–µ—Ç:", "–í–æ–ø—Ä–æ—Å:"]:
            if answer.startswith(phrase):
                answer = answer[len(phrase):].strip()

        return answer

    except Exception as e:
        if DEBUG_MODE:
            print(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        return "‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."


def process_request(message):
    global all_texts, saved_requests, faiss_index, text_chunks

    if not all_texts:
        bot.send_message(message.chat.id, "‚ùå –ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞.")
        return

    if faiss_index is None or len(text_chunks) == 0:
        bot.send_message(message.chat.id,
                         "‚è≥ –°–æ–∑–¥–∞—é –∏–Ω–¥–µ–∫—Å –¥–ª—è –ø–æ–∏—Å–∫–∞... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")
        if not process_and_embed_chunks():
            bot.send_message(message.chat.id, "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–Ω–¥–µ–∫—Å–∞ –ø–æ–∏—Å–∫–∞.")
            return

    prompt = saved_requests[-1]
    bot.send_message(message.chat.id, "üîç –ò—â—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö...")
    relevant_chunks = find_relevant_chunks(prompt, top_k=5)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤

    if not relevant_chunks:
        bot.send_message(message.chat.id, "‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.")
        return

    context = "\n\n".join(relevant_chunks)

    if DEBUG_MODE:
        mode = "GPU" if gpu_available else "CPU"
        bot.send_message(message.chat.id, f"‚öôÔ∏è –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å (–Ω–∞ {mode})...")
        bot.send_message(message.chat.id, f"üìö –ò—Å–ø–æ–ª—å–∑—É—é {len(relevant_chunks)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
    else:
        bot.send_message(message.chat.id, "‚öôÔ∏è –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...")

    bot.send_message(message.chat.id, "üß† –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç...")
    response = generate_response(prompt, context)

    # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ —á–∞—Å—Ç–∏
    max_length = 4000
    if len(response) > max_length:
        for i in range(0, len(response), max_length):
            bot.send_message(message.chat.id, response[i:i + max_length])
    else:
        bot.send_message(message.chat.id, f"üìù –û—Ç–≤–µ—Ç –Ω–∞ –≤–∞—à –∑–∞–ø—Ä–æ—Å:\n\n{response}")


@bot.message_handler(commands=['start'])
def start(message):
    markup = types.ReplyKeyboardMarkup(resize_keyboard=True)
    btn1 = types.KeyboardButton("üëã –ò —Ç–µ–±–µ –Ω–µ —Ö–≤–æ—Ä–∞—Ç—å")
    markup.add(btn1)
    bot.send_message(message.chat.id,
                     "üëã –ü—Ä–∏–≤–µ—Ç! –Ø –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ. –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã (PDF, DOCX, TXT), –∞ –∑–∞—Ç–µ–º –∑–∞–¥–∞–≤–∞–π –≤–æ–ø—Ä–æ—Å—ã –ø–æ –∏—Ö —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É.",
                     reply_markup=markup)


@bot.message_handler(content_types=['text', 'document'])
def handle_files(message):
    global all_texts, text_chunks, faiss_index, saved_requests

    if message.document:
        file_info = bot.get_file(message.document.file_id)
        file_name = message.document.file_name
        file_bytes = bot.download_file(file_info.file_path)

        try:
            if file_name.lower().endswith('.txt'):
                text = extract_text_from_txt(file_bytes)
            elif file_name.lower().endswith('.pdf'):
                text = extract_text_from_pdf(file_bytes)
            elif file_name.lower().endswith(('.docx', '.doc')):
                text = extract_text_from_docx(file_bytes)
            else:
                bot.reply_to(message, '‚ùå –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã .txt, .pdf –∏ .docx')
                return

            all_texts.append(text)
            text_chunks = []
            faiss_index = None

            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∞–π–ª–µ
            if DEBUG_MODE:
                print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(all_texts)}")
                print(f"–†–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–∞: {len(text.split())} —Å–ª–æ–≤")
                print(f"–ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤: {text[:200]}...")

            bot.reply_to(message, f"üìÑ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω: {file_name}\n\n–¢–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω: {len(text.split())} —Å–ª–æ–≤")

        except Exception as er:
            error_msg = f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {er}"
            if DEBUG_MODE:
                error_msg += "\n\n–ü–æ–¥—Å–∫–∞–∑–∫–∞: –§–∞–π–ª –º–æ–∂–µ—Ç –∏–º–µ—Ç—å –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É –∏–ª–∏ –±—ã—Ç—å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω"
            bot.reply_to(message, error_msg)

    elif message.text:
        if message.text == 'üëã –ò —Ç–µ–±–µ –Ω–µ —Ö–≤–æ—Ä–∞—Ç—å':
            markup = types.ReplyKeyboardMarkup(resize_keyboard=True)
            btn1 = types.KeyboardButton("–î–æ–±–∞–≤–∏—Ç—å —Ñ–∞–π–ª")
            btn2 = types.KeyboardButton('–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª')
            btn3 = types.KeyboardButton('–£–¥–∞–ª–∏—Ç—å –≤—Å–µ —Ñ–∞–π–ª—ã')
            btn4 = types.KeyboardButton("üìù –ù–∞–ø–∏—Å–∞—Ç—å –∑–∞–ø—Ä–æ—Å")
            btn6 = types.KeyboardButton("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–Ω–¥–µ–∫—Å")
            btn7 = types.KeyboardButton("üì• –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏–Ω–¥–µ–∫—Å")

            if DEBUG_MODE:
                btn5 = types.KeyboardButton("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ")
                markup.add(btn1, btn2, btn3, btn4, btn5, btn6, btn7)
            else:
                markup.add(btn1, btn2, btn3, btn4)

            bot.send_message(message.chat.id, '–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:', reply_markup=markup)

        elif message.text == '–î–æ–±–∞–≤–∏—Ç—å —Ñ–∞–π–ª':
            bot.send_message(message.chat.id, '–ü—Ä–∏—Å—ã–ª–∞–π—Ç–µ —Ñ–∞–π–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ PDF, DOCX –∏–ª–∏ TXT')

        elif message.text == '–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª':
            if not all_texts:
                bot.send_message(message.chat.id, "‚ùå –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞.")
            else:
                bot.send_message(message.chat.id,
                                 "‚è≥ –°–æ–∑–¥–∞—é –∏–Ω–¥–µ–∫—Å –¥–ª—è –ø–æ–∏—Å–∫–∞... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")
                if process_and_embed_chunks():
                    bot.send_message(message.chat.id, f"‚úÖ –ò–Ω–¥–µ–∫—Å —Å–æ–∑–¥–∞–Ω! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(text_chunks)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
                else:
                    bot.send_message(message.chat.id, "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–Ω–¥–µ–∫—Å–∞")

        elif message.text == '–£–¥–∞–ª–∏—Ç—å –≤—Å–µ —Ñ–∞–π–ª—ã':
            all_texts = []
            saved_requests = []
            text_chunks = []
            faiss_index = None
            bot.send_message(message.chat.id, '‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã, –∑–∞–ø—Ä–æ—Å—ã –∏ –∏–Ω–¥–µ–∫—Å—ã —É–¥–∞–ª–µ–Ω—ã')
            
            #–î–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤ –Ω–∞ –¥–∏—Å–∫–µ
            try:
                os.remove("faiss_index.index")
            except FileNotFoundError:
                pass

            try:
                os.remove("text_chunks.pkl")
            except FileNotFoundError:
                pass

        elif message.text == 'üìù –ù–∞–ø–∏—Å–∞—Ç—å –∑–∞–ø—Ä–æ—Å':
            bot.send_message(message.chat.id, "–ù–∞–ø–∏—à–∏ —Å–≤–æ–π –∑–∞–ø—Ä–æ—Å –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:")
            bot.register_next_step_handler(message, save_request)

        elif message.text == 'üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–Ω–¥–µ–∫—Å':
            if faiss_index is None:
                bot.send_message(message.chat.id, "‚ùå –ò–Ω–¥–µ–∫—Å –Ω–µ —Å–æ–∑–¥–∞–Ω")
            else:
                try:
                    faiss.write_index(faiss_index, "faiss_index.index")
                    bot.send_message(message.chat.id, "‚úÖ –ò–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª faiss_index.index")
                except Exception as e:
                    bot.send_message(message.chat.id, f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {str(e)}")

        elif message.text == 'üì• –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏–Ω–¥–µ–∫—Å':
            if not os.path.exists("faiss_index.index"):
                bot.send_message(message.chat.id, "‚ùå –§–∞–π–ª –∏–Ω–¥–µ–∫—Å–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω")
            else:
                try:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é, –æ–±—ä—è–≤–ª–µ–Ω–Ω—É—é –≤ –Ω–∞—á–∞–ª–µ —Ñ—É–Ω–∫—Ü–∏–∏
                    faiss_index = faiss.read_index("faiss_index.index")

                    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º text_chunks –∏–∑ —Ñ–∞–π–ª–∞ (–¥–ª—è –ø—Ä–∏–º–µ—Ä–∞ - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –æ—Ç–¥–µ–ª—å–Ω–æ)
                    bot.send_message(message.chat.id,
                                     "‚úÖ –ò–Ω–¥–µ–∫—Å –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ —Ñ–∞–π–ª–∞\n‚ö†Ô∏è –¢–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã, –Ω—É–∂–Ω–æ –ø–µ—Ä–µ—Å—Ç—Ä–æ–∏—Ç—å –∏–Ω–¥–µ–∫—Å")
                except Exception as e:
                    bot.send_message(message.chat.id, f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}")

        elif message.text == '‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ' and DEBUG_MODE:
            try:
                pytorch_info = f"PyTorch: {torch.__version__}\nCUDA: {torch.cuda.is_available()}"
                emb_info = f"Embedding model: {embedding_model._modules['0'].auto_model.config._name_or_path}"
                faiss_info = f"FAISS: {faiss_index.ntotal} –≤–µ–∫—Ç–æ—Ä–æ–≤" if faiss_index else "FAISS: –∏–Ω–¥–µ–∫—Å –Ω–µ —Å–æ–∑–¥–∞–Ω"
                model_info = ollama.show(model_name)
                parameters = model_info.get('parameters', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')

                info_msg = (
                    "‚öôÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ:\n"
                    f"‚Ä¢ –ú–æ–¥–µ–ª—å: {model_name}\n"
                    f"‚Ä¢ –†–µ–∂–∏–º: {'GPU' if gpu_available else 'CPU'}\n"
                    f"‚Ä¢ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {parameters}\n"
                    f"‚Ä¢ {emb_info}\n"
                    f"‚Ä¢ {faiss_info}\n\n"
                    f"PyTorch –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:\n{pytorch_info}"
                )

                bot.send_message(message.chat.id, info_msg)
            except Exception as e:
                bot.send_message(message.chat.id, f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {str(e)}")


bot.polling(none_stop=True, interval=0)